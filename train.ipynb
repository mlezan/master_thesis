{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"train.ipynb","provenance":[{"file_id":"1bQ_B_WndZjzVrGfk1ZS4YcfW484BWSbq","timestamp":1614698927250}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L0ORwcBt_2SG","executionInfo":{"status":"ok","timestamp":1614706276239,"user_tz":-60,"elapsed":3955,"user":{"displayName":"Monika Bart","photoUrl":"","userId":"15479740792331365535"}},"outputId":"b99ec4dc-3243-4e6e-af71-85cd4a7b9529"},"source":["### This code is based on the following code bases:\n","### https://machinelearningmastery.com/how-to-train-a-progressive-growing-gan-in-keras-for-synthesizing-faces/\n","### And has borrowed some functionalities from:\n","### https://github.com/MSC-BUAA/Keras-progressive_growing_of_gans/blob/master/Progressive%20growing%20of%20GANs/train.py\n","### https://github.com/PacktPublishing/Hands-On-Generative-Adversarial-Networks-with-Keras/blob/ac1b8af1678af352e7e9efdcc6a3e829c6aed294/Chapter09/train_wgan_gp.py\n","### and has been further developed by Monika Lezanska and Bart Driessen for our thesis on generating neuroimaging data.\n","### The dataset used in this study can be downloaded from: https://www.kaggle.com/sartajbhuvaji/brain-tumor-classification-mri\n","\n","import os\n","import numpy as np\n","from PIL import Image\n","from matplotlib import pyplot as plt\n","import math\n","from numpy.random import randn, randint\n","from skimage.transform import resize, rotate\n","from keras.optimizers import Adam\n","from keras.models import Sequential, Model, load_model\n","from keras.layers import Input, Dense, Flatten, Reshape, Conv2D, UpSampling2D, AveragePooling2D, LeakyReLU, Layer, Add\n","import keras\n","from keras.initializers import RandomNormal\n","from keras import backend\n","from functools import partial\n","import pandas as pd\n","\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\", force_remount=True)\n","\n","os.chdir('/content/gdrive/MyDrive/master_thesis/Notebooks/pggan')\n","\n","from custom_layers import *\n","from losses import *\n","\n","from keras.utils.generic_utils import get_custom_objects\n","get_custom_objects().update({\"wasserstein_loss\": wasserstein_loss})\n","\n","from model import *\n","from preprocessing import *\n","from helper import *\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pLSSLI23kotS","executionInfo":{"status":"ok","timestamp":1614706276241,"user_tz":-60,"elapsed":3946,"user":{"displayName":"Monika Bart","photoUrl":"","userId":"15479740792331365535"}}},"source":["def train_epochs(g_model, d_model, gan_model, dataset, n_epochs, n_batch, fadein=False, output_folder=\"results4\"):\n","  \"\"\"\n","  Function to train a single model, either tuned or faded, on just one resolution\n","  Parameters:\n","    g_model: the generator \n","    d_model: the discriminator\n","    gan_model: the combined model to train the generator\n","    dataset: the dataset, preprocessed / rescaled\n","    n_epochs: the number of epochs\n","    n_batch: the batch size\n","    fadein: boolean checking whether it's the faded model that's being trained\n","    output_folder: output folder to store the losses\n","  Returns:\n","    nothing but trains both discriminator and generator, and stores the losses\n","  \"\"\"\n","  bat_per_epo = int(dataset.shape[0] / n_batch)\n","  n_steps = bat_per_epo * n_epochs\n","  half_batch = int(n_batch / 2)\n","  losses = []\n","  for i in range(n_steps):\n","    if fadein:\n","      update_fadein([g_model, d_model, gan_model], i, n_steps)\n","    X_real, y_real = generate_real_samples(dataset, half_batch)\n","    X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n","    d_loss1 = d_model.train_on_batch(X_real, y_real)\n","    d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n","    z_input = generate_latent_points(latent_dim, n_batch)\n","    y_real2 = np.ones((n_batch, 1))\n","    g_loss = gan_model.train_on_batch(z_input, y_real2)\n","    print('>%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, d_loss1, d_loss2, g_loss))\n","    losses.append({'step':i+1, 'd_loss1':d_loss1, 'd_loss2':d_loss2, 'g_loss':g_loss})\n","  faded = \"faded\" if fadein else \"tuned\"\n","  pd.DataFrame(losses).to_csv(output_folder+\"/\"+str(dataset.shape[-2])+\"x\"+str(dataset.shape[-2])+faded+\"losses.csv\")\n","\n","def train(g_models, d_models, gan_models, dataset, latent_dim, e_norm, e_fadein, n_batch, pretrained_mods=None, faded=False, output_folder=\"results4\"):\n","  \"\"\"\n","  train the generators and the discriminators of the entire model - multiple growing stages, both tuned and faded\n","  Parameters:\n","    g_models: generator models\n","    d_models: discriminator models\n","    gan_models: combined models to train generator\n","    dataset: the input dataset (unpreprocessed)\n","    latent_dim: the size of the input noise vector\n","    e_norm: nr epochs for the tuned model\n","    e_fadein: nr epochs for the faded model\n","    n_batch: batch size\n","    pretrained_mods: list of three models that have already been trained up to a certain resolution. in form [g_model, d_model, gan_model]\n","    faded: boolean indicating whether last one of the pretrained models was faded\n","    output_folder: output folder to store results\n","  Returns:\n","    no output but does the training and writes all results via the summarize_performance and train_epochs methods\n","  \"\"\"\n","  if not pretrained_mods:\n","    g_normal, d_normal, gan_normal = g_models[0][0], d_models[0][0], gan_models[0][0]\n","    gen_shape = g_normal.output_shape\n","    scaled_data = scale_dataset(dataset, gen_shape[1:])\n","    print('Scaled Data', scaled_data.shape)\n","    train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[0], n_batch[0], output_folder=output_folder)\n","    summarize_performance('tuned', g_normal, d_normal, gan_normal, latent_dim, output_folder=output_folder)\n","    starting_i = 1\n","  else:\n","    a_mod = pretrained_mods[0]\n","    gen_shape = a_mod.output_shape\n","    scaled_data = scale_dataset(dataset, gen_shape[1:])\n","    starting_i = int(math.log(a_mod.output_shape[-2])/math.log(2))-1\n","    if faded:\n","      starting_i -= 1\n","    print('Scaled Data', scaled_data.shape)\n","  for i in range(starting_i, len(g_models)):\n","    print(\"batchsize\",n_batch[i])\n","    print(\"epochs\",e_norm[i])\n","    [g_normal, g_fadein] = g_models[i]\n","    [d_normal, d_fadein] = d_models[i]\n","    [gan_normal, gan_fadein] = gan_models[i]\n","    gen_shape = g_normal.output_shape\n","    scaled_data = scale_dataset(dataset, gen_shape[1:])\n","    print('Scaled Data', scaled_data.shape)\n","    if not faded or i > starting_i:\n","      train_epochs(g_fadein, d_fadein, gan_fadein, scaled_data, e_fadein[i], n_batch[i], True, output_folder=output_folder)\n","      summarize_performance('faded', g_fadein, d_fadein, gan_fadein, latent_dim, output_folder=output_folder)\n","    train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[i], n_batch[i], output_folder=output_folder)\n","    summarize_performance('tuned', g_normal, d_normal, gan_normal, latent_dim, output_folder=output_folder)\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mGExTxAEAiAx","executionInfo":{"status":"ok","timestamp":1614706276586,"user_tz":-60,"elapsed":4287,"user":{"displayName":"Monika Bart","photoUrl":"","userId":"15479740792331365535"}},"outputId":"8e74501f-b31c-4081-9083-de0dba86176f"},"source":["dataset = load_real_samples('img_align_braint_128.npz')\n","print('Loaded', dataset.shape)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Loaded (641, 128, 128, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GfzmSHex1UQi","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1614706424855,"user_tz":-60,"elapsed":152546,"user":{"displayName":"Monika Bart","photoUrl":"","userId":"15479740792331365535"}},"outputId":"de821643-e550-4c7d-b347-3ac8b73dd9f4"},"source":["n_blocks = 6 ### number of growth phases, e.g. 6 == [4, 8, 16, 32, 64, 128]\n","latent_dim = 100 ### size of the latent space\n","d_models = define_discriminator(n_blocks)\n","g_models = define_generator(latent_dim, n_blocks)\n","gan_models = define_composite(d_models, g_models)\n","\n","n_batch = [32, 32, 32, 32, 32, 32]\n","n_epochs = [100, 100, 100, 100, 200, 300]\n","\n","input_folder = \"final_results\"\n","model_size = \"064x064\"\n","model_type = \"tuned\" ### was the last trained model \"tuned\" of \"faded\"?\n","g_model = load_model(input_folder+'/g_model_'+model_size+\"-\"+model_type)\n","d_model = load_model(input_folder+'/d_model_'+model_size+\"-\"+model_type)\n","gan_model = load_model(input_folder+'/gan_model_'+model_size+\"-\"+model_type)\n","train(g_models, d_models, gan_models, dataset, latent_dim, n_epochs, n_epochs, n_batch, [g_model, d_model, gan_model], faded=model_type==\"faded\", output_folder=\"final_results\")"],"execution_count":4,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n","Scaled Data (1923, 64, 64, 3)\n","batchsize 32\n","epochs 300\n","Scaled Data (1923, 128, 128, 3)\n",">1, d1=0.000, d2=0.000 g=-0.000\n",">2, d1=-0.000, d2=0.000 g=-0.000\n",">3, d1=-0.000, d2=0.000 g=-0.000\n",">4, d1=-0.000, d2=0.000 g=-0.000\n",">5, d1=-0.000, d2=0.000 g=-0.000\n",">6, d1=-0.000, d2=0.000 g=-0.000\n",">7, d1=-0.000, d2=0.000 g=-0.000\n",">8, d1=-0.000, d2=0.000 g=0.000\n",">9, d1=-0.000, d2=0.000 g=0.000\n",">10, d1=-0.000, d2=0.000 g=0.000\n",">11, d1=-0.000, d2=0.000 g=0.000\n",">12, d1=-0.000, d2=0.000 g=0.000\n",">13, d1=-0.000, d2=0.000 g=-0.000\n",">14, d1=-0.000, d2=0.000 g=-0.000\n",">15, d1=-0.000, d2=0.000 g=-0.000\n",">16, d1=-0.000, d2=0.000 g=-0.000\n",">17, d1=-0.000, d2=0.000 g=-0.000\n",">18, d1=-0.000, d2=0.000 g=-0.000\n",">19, d1=-0.000, d2=0.000 g=-0.000\n",">20, d1=-0.000, d2=0.000 g=-0.000\n",">21, d1=-0.000, d2=0.000 g=-0.000\n",">22, d1=-0.000, d2=0.000 g=-0.000\n",">23, d1=-0.000, d2=0.000 g=-0.000\n",">24, d1=-0.000, d2=0.000 g=-0.000\n",">25, d1=-0.000, d2=0.000 g=-0.000\n",">26, d1=-0.000, d2=0.000 g=-0.000\n",">27, d1=-0.000, d2=0.000 g=-0.000\n",">28, d1=-0.000, d2=0.000 g=-0.000\n",">29, d1=-0.000, d2=0.000 g=-0.000\n",">30, d1=-0.000, d2=0.000 g=0.000\n",">31, d1=-0.000, d2=0.000 g=0.000\n",">32, d1=-0.000, d2=0.000 g=-0.000\n",">33, d1=-0.000, d2=0.000 g=0.000\n",">34, d1=-0.000, d2=0.000 g=0.000\n",">35, d1=-0.000, d2=0.000 g=0.000\n",">36, d1=-0.000, d2=0.000 g=0.000\n",">37, d1=-0.000, d2=0.000 g=-0.000\n",">38, d1=-0.000, d2=0.000 g=-0.000\n",">39, d1=-0.000, d2=0.000 g=-0.000\n",">40, d1=-0.000, d2=0.000 g=-0.000\n",">41, d1=-0.000, d2=0.000 g=-0.000\n",">42, d1=-0.000, d2=0.000 g=-0.000\n",">43, d1=-0.000, d2=0.000 g=-0.000\n",">44, d1=-0.000, d2=0.000 g=-0.000\n",">45, d1=-0.000, d2=0.000 g=-0.000\n",">46, d1=-0.000, d2=0.000 g=-0.000\n",">47, d1=-0.000, d2=0.000 g=-0.000\n",">48, d1=-0.000, d2=0.000 g=-0.000\n",">49, d1=-0.000, d2=0.000 g=-0.000\n",">50, d1=-0.000, d2=0.000 g=-0.000\n",">51, d1=-0.000, d2=0.000 g=-0.000\n",">52, d1=-0.000, d2=0.000 g=-0.000\n",">53, d1=-0.000, d2=0.000 g=-0.000\n",">54, d1=-0.000, d2=0.000 g=-0.000\n",">55, d1=-0.000, d2=0.000 g=-0.000\n",">56, d1=-0.000, d2=0.000 g=-0.000\n",">57, d1=-0.000, d2=0.000 g=-0.000\n",">58, d1=-0.000, d2=0.000 g=-0.000\n",">59, d1=-0.000, d2=0.000 g=-0.000\n",">60, d1=-0.000, d2=0.000 g=-0.000\n",">61, d1=-0.000, d2=0.000 g=-0.000\n",">62, d1=-0.000, d2=0.000 g=-0.000\n",">63, d1=-0.000, d2=0.000 g=-0.000\n",">64, d1=-0.000, d2=0.000 g=-0.000\n",">65, d1=-0.000, d2=0.000 g=-0.000\n",">66, d1=-0.000, d2=0.000 g=-0.000\n",">67, d1=-0.000, d2=0.000 g=-0.000\n",">68, d1=-0.000, d2=0.000 g=-0.000\n",">69, d1=-0.000, d2=0.000 g=-0.000\n",">70, d1=-0.000, d2=0.000 g=-0.000\n",">71, d1=-0.000, d2=0.000 g=-0.000\n",">72, d1=-0.000, d2=0.000 g=-0.000\n",">73, d1=-0.000, d2=0.000 g=-0.000\n",">74, d1=-0.000, d2=0.000 g=-0.000\n",">75, d1=-0.000, d2=0.000 g=-0.000\n",">76, d1=-0.000, d2=0.000 g=-0.000\n",">77, d1=-0.000, d2=0.000 g=-0.000\n",">78, d1=-0.000, d2=0.000 g=-0.000\n",">79, d1=-0.000, d2=0.000 g=-0.000\n",">80, d1=-0.000, d2=0.000 g=-0.000\n",">81, d1=-0.000, d2=0.000 g=-0.000\n",">82, d1=-0.000, d2=0.000 g=-0.000\n",">83, d1=-0.000, d2=0.000 g=-0.000\n",">84, d1=-0.000, d2=0.000 g=-0.000\n",">85, d1=-0.000, d2=0.000 g=-0.000\n",">86, d1=-0.000, d2=0.000 g=-0.000\n",">87, d1=-0.000, d2=0.000 g=-0.000\n",">88, d1=-0.000, d2=0.000 g=-0.000\n",">89, d1=-0.000, d2=0.000 g=-0.000\n",">90, d1=-0.000, d2=0.000 g=-0.000\n",">91, d1=-0.000, d2=0.000 g=-0.000\n",">92, d1=-0.000, d2=0.000 g=-0.000\n",">93, d1=-0.000, d2=0.000 g=-0.000\n",">94, d1=-0.000, d2=0.000 g=-0.000\n",">95, d1=-0.000, d2=0.000 g=-0.000\n",">96, d1=-0.000, d2=0.000 g=-0.000\n",">97, d1=-0.000, d2=0.000 g=-0.000\n",">98, d1=-0.000, d2=0.000 g=-0.000\n",">99, d1=-0.000, d2=0.000 g=-0.000\n",">100, d1=-0.000, d2=0.000 g=-0.000\n",">101, d1=-0.000, d2=0.000 g=-0.000\n",">102, d1=-0.000, d2=0.000 g=-0.000\n",">103, d1=-0.000, d2=0.000 g=-0.000\n",">104, d1=-0.000, d2=0.000 g=-0.000\n",">105, d1=-0.000, d2=0.000 g=-0.000\n",">106, d1=-0.000, d2=0.000 g=-0.000\n",">107, d1=-0.000, d2=0.000 g=-0.000\n",">108, d1=-0.000, d2=0.000 g=-0.000\n",">109, d1=-0.000, d2=0.000 g=-0.000\n",">110, d1=-0.000, d2=0.000 g=-0.000\n",">111, d1=-0.000, d2=0.000 g=-0.000\n",">112, d1=-0.000, d2=0.000 g=-0.000\n",">113, d1=-0.000, d2=0.000 g=-0.000\n",">114, d1=-0.000, d2=0.000 g=-0.000\n",">115, d1=-0.000, d2=0.000 g=-0.000\n",">116, d1=-0.000, d2=0.000 g=-0.000\n",">117, d1=-0.000, d2=0.000 g=-0.000\n",">118, d1=-0.000, d2=0.000 g=-0.000\n",">119, d1=-0.000, d2=0.000 g=-0.000\n",">120, d1=-0.000, d2=0.000 g=-0.000\n",">121, d1=-0.000, d2=0.000 g=-0.000\n",">122, d1=-0.000, d2=0.000 g=-0.000\n",">123, d1=-0.000, d2=0.000 g=-0.000\n",">124, d1=-0.000, d2=0.000 g=-0.000\n",">125, d1=-0.000, d2=0.000 g=-0.000\n",">126, d1=-0.000, d2=0.000 g=-0.000\n",">127, d1=-0.000, d2=0.000 g=-0.000\n",">128, d1=-0.000, d2=0.000 g=-0.000\n",">129, d1=-0.000, d2=0.000 g=-0.000\n",">130, d1=-0.000, d2=0.000 g=-0.000\n",">131, d1=-0.000, d2=0.000 g=-0.000\n",">132, d1=-0.000, d2=0.000 g=0.000\n",">133, d1=-0.000, d2=0.000 g=-0.000\n",">134, d1=-0.000, d2=0.000 g=-0.000\n",">135, d1=-0.000, d2=0.000 g=-0.000\n",">136, d1=-0.000, d2=0.000 g=-0.000\n",">137, d1=-0.000, d2=0.000 g=-0.000\n",">138, d1=-0.000, d2=0.000 g=-0.000\n",">139, d1=-0.000, d2=0.000 g=-0.000\n",">140, d1=-0.000, d2=0.000 g=-0.000\n",">141, d1=-0.000, d2=0.000 g=-0.000\n",">142, d1=-0.000, d2=0.000 g=-0.000\n",">143, d1=-0.000, d2=0.000 g=-0.000\n",">144, d1=-0.000, d2=0.000 g=-0.000\n",">145, d1=-0.000, d2=0.000 g=-0.000\n",">146, d1=-0.000, d2=0.000 g=-0.000\n",">147, d1=-0.000, d2=0.000 g=-0.000\n",">148, d1=-0.000, d2=0.000 g=-0.000\n",">149, d1=-0.000, d2=0.000 g=-0.000\n",">150, d1=-0.000, d2=0.000 g=-0.000\n",">151, d1=-0.000, d2=0.001 g=-0.000\n",">152, d1=-0.000, d2=0.001 g=-0.000\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-e412a5c7ef85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0md_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/d_model_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodel_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mgan_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/gan_model_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodel_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"faded\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"final_results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-2-d7ff53d603e5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_models, d_models, gan_models, dataset, latent_dim, e_norm, e_fadein, n_batch, pretrained_mods, faded, output_folder)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Scaled Data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfaded\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstarting_i\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m       \u001b[0mtrain_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_fadein\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_fadein\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_fadein\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_fadein\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m       \u001b[0msummarize_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'faded'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_fadein\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_fadein\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_fadein\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mtrain_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_norm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-d7ff53d603e5>\u001b[0m in \u001b[0;36mtrain_epochs\u001b[0;34m(g_model, d_model, gan_model, dataset, n_epochs, n_batch, fadein, output_folder)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mX_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0md_loss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0md_loss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mz_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0my_real2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1730\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1731\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1667\u001b[0m     \"\"\"\n\u001b[1;32m   1668\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m       \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m   def train_on_batch(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   3704\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly_outside_functions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3705\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtuples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3706\u001b[0;31m       \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3707\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3708\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m    891\u001b[0m             (tensor_name, self._shape, value_tensor.shape))\n\u001b[1;32m    892\u001b[0m       assign_op = gen_resource_variable_ops.assign_variable_op(\n\u001b[0;32m--> 893\u001b[0;31m           self.handle, value_tensor, name=name)\n\u001b[0m\u001b[1;32m    894\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36massign_variable_op\u001b[0;34m(resource, value, name)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m--> 142\u001b[0;31m         _ctx, \"AssignVariableOp\", name, resource, value)\n\u001b[0m\u001b[1;32m    143\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}